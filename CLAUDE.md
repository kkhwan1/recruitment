# CLAUDE.md - ì±„ìš©ì‹œìŠ¤í…œ í”„ë¡œì íŠ¸ ê°€ì´ë“œ

ì´ íŒŒì¼ì€ Claude Codeê°€ ì´ ì €ì¥ì†Œì˜ ì½”ë“œë¥¼ ì‘ì—…í•  ë•Œ ì°¸ê³ í•˜ëŠ” ê°€ì´ë“œì…ë‹ˆë‹¤.

## í”„ë¡œì íŠ¸ ê°œìš”

**ì±„ìš© ê³µê³  ë¶„ì„ ì‹œìŠ¤í…œ** - ê¸°ìˆ  ìœ ì¶œ ì˜ì‹¬ ê³µê³  íƒì§€ ë° ìœ„í—˜ë„ ë¶„ì„ ìë™í™” ì‹œìŠ¤í…œ

### í•µì‹¬ ê¸°ëŠ¥
- ğŸ” **ë‹¤ì¤‘ ì±„ìš© ì‚¬ì´íŠ¸ í¬ë¡¤ë§**: JobKorea, Incruit, Saramin, Hibrain ì§€ì›
- ğŸ¯ **3ë‹¨ê³„ í‚¤ì›Œë“œ íƒì§€**: ê¸°ìˆ /ì˜ì‹¬/ìœ„í—˜ í‚¤ì›Œë“œ ì²´ê³„ì  ë¶„ë¥˜
- âš ï¸ **ë³µí•© íŒ¨í„´ ë§¤ì¹­**: 2-3ê°œ í‚¤ì›Œë“œ ì¡°í•©ìœ¼ë¡œ ê³ ìœ„í—˜ íŒ¨í„´ íƒì§€
- ğŸ“Š **ìœ„í—˜ë„ ì ìˆ˜ ì‚°ì •**: ê°€ì¤‘ì¹˜ ê¸°ë°˜ ìë™ ì ìˆ˜ ê³„ì‚° ë° ë“±ê¸‰ ë¶„ë¥˜
- ğŸ’¾ **ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥**: SQLite ê¸°ë°˜ ì§€ì†ì  ë°ì´í„° ê´€ë¦¬
- ğŸ“ˆ **ì¼ì¼ ë¦¬í¬íŠ¸ ìƒì„±**: íƒì§€ ê²°ê³¼ ìë™ ìš”ì•½ ë° ë¶„ì„

## í”„ë¡œì íŠ¸ êµ¬ì¡°

```
ì±„ìš©ì‹œìŠ¤í…œ/
â”œâ”€â”€ config/                      # ì„¤ì • íŒŒì¼
â”‚   â”œâ”€â”€ keywords.csv            # í‚¤ì›Œë“œ ë°ì´í„°ë² ì´ìŠ¤ (tier, category, weight)
â”‚   â””â”€â”€ patterns.csv            # ë³µí•© íŒ¨í„´ ì •ì˜
â”œâ”€â”€ sites/                       # í¬ë¡¤ëŸ¬ êµ¬í˜„
â”‚   â”œâ”€â”€ jobkorea/               # JobKorea í¬ë¡¤ëŸ¬
â”‚   â”œâ”€â”€ incruit/                # Incruit í¬ë¡¤ëŸ¬
â”‚   â”œâ”€â”€ saramin/                # Saramin í¬ë¡¤ëŸ¬
â”‚   â””â”€â”€ hibrain/                # Hibrain í¬ë¡¤ëŸ¬
â”œâ”€â”€ analyzers/                   # ë¶„ì„ ì—”ì§„
â”‚   â”œâ”€â”€ keyword_detector.py     # í‚¤ì›Œë“œ íƒì§€ ì—”ì§„
â”‚   â””â”€â”€ risk_scorer.py          # ìœ„í—˜ë„ ì ìˆ˜ ê³„ì‚°ê¸°
â”œâ”€â”€ database/                    # ë°ì´í„°ë² ì´ìŠ¤ ë ˆì´ì–´
â”‚   â”œâ”€â”€ models.py               # ë°ì´í„° ëª¨ë¸
â”‚   â””â”€â”€ repositories.py         # Repository íŒ¨í„´ êµ¬í˜„
â”œâ”€â”€ utils/                       # ìœ í‹¸ë¦¬í‹°
â”‚   â”œâ”€â”€ logger.py               # ë¡œê¹… ì„¤ì •
â”‚   â””â”€â”€ text_utils.py           # í…ìŠ¤íŠ¸ ì •ì œ
â”œâ”€â”€ data/                        # ë°ì´í„° ì €ì¥ì†Œ
â”‚   â”œâ”€â”€ json_results/           # JSON ë°±ì—…
â”‚   â””â”€â”€ recruitment.db          # SQLite ë°ì´í„°ë² ì´ìŠ¤
â”œâ”€â”€ main.py                      # CLI ì§„ì…ì 
â”œâ”€â”€ crawl_and_analyze.py        # í†µí•© ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ test_analysis_system.py     # ë¶„ì„ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
```

## ë¹ ë¥¸ ì‹œì‘

### 1. í™˜ê²½ ì„¤ì •

```bash
# Python ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# Playwright ë¸Œë¼ìš°ì € ì„¤ì¹˜
playwright install chromium
```

### 2. ê¸°ë³¸ ì‹¤í–‰

```bash
# ëª¨ë“  ì‚¬ì´íŠ¸, ëª¨ë“  í‚¤ì›Œë“œë¡œ í¬ë¡¤ë§ ë° ë¶„ì„
python crawl_and_analyze.py

# íŠ¹ì • ì‚¬ì´íŠ¸ë§Œ í¬ë¡¤ë§
python main.py --site jobkorea

# íŠ¹ì • í‚¤ì›Œë“œë¡œ ê²€ìƒ‰
python main.py --keyword "ë°˜ë„ì²´"

# ìµœëŒ€ ìˆ˜ì§‘ ê°œìˆ˜ ì œí•œ
python main.py --max-jobs 50

# ë¸Œë¼ìš°ì € í‘œì‹œ (ë””ë²„ê¹…ìš©)
python main.py --no-headless
```

### 3. ì‚°ì—…ë³„ í¬ë¡¤ë§ (JobKorea)

```bash
# íŠ¹ì • ì‚°ì—… í•„í„°ë§
python sites/jobkorea/crawler.py --industry "ë°˜ë„ì²´"
python sites/jobkorea/crawler.py --industry "ë””ìŠ¤í”Œë ˆì´"
python sites/jobkorea/crawler.py --industry "ì´ì°¨ì „ì§€"
```

### 4. ë¶„ì„ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸

```bash
# í‚¤ì›Œë“œ íƒì§€ ë° ìœ„í—˜ë„ ë¶„ì„ í…ŒìŠ¤íŠ¸
python test_analysis_system.py
```

## ì•„í‚¤í…ì²˜ íŒ¨í„´

### 1. í¬ë¡¤ëŸ¬ êµ¬í˜„ íŒ¨í„´

ëª¨ë“  ì‚¬ì´íŠ¸ í¬ë¡¤ëŸ¬ëŠ” ì¼ê´€ëœ íŒ¨í„´ì„ ë”°ë¦…ë‹ˆë‹¤:

```python
from playwright.sync_api import sync_playwright
import time

class SiteCrawler:
    def __init__(self, headless: bool = True):
        self.headless = headless
        self.config = self._load_config()

    def start(self):
        """ë¸Œë¼ìš°ì € ì‹œì‘ ë° Bot Detection íšŒí”¼ ì„¤ì •"""
        self.playwright = sync_playwright().start()

        # Bot Detection íšŒí”¼ ì„¤ì •
        self.browser = self.playwright.chromium.launch(
            headless=self.headless,
            args=[
                '--disable-blink-features=AutomationControlled',
                '--no-sandbox',
                '--disable-dev-shm-usage',
            ]
        )

        # User-Agent ì„¤ì •
        self.page = self.browser.new_page(
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        )

        # navigator.webdriver ì œê±°
        self.page.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined
            });
        """)

    def crawl(self, keyword: str, max_jobs: int = 50) -> List[Dict]:
        """í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•˜ì—¬ ê³µê³  ìˆ˜ì§‘"""
        # êµ¬í˜„ ë¡œì§
        pass
```

### 2. React SPA í¬ë¡¤ë§ íŒ¨í„´ (Hibrain)

React ê¸°ë°˜ SPAëŠ” íŠ¹ë³„í•œ ëŒ€ê¸° ì „ëµì´ í•„ìš”í•©ë‹ˆë‹¤:

```python
def get_job_list_with_preview(self, list_type: str = "ING", max_jobs: int = 50):
    """4ë‹¨ê³„ ê³„ì¸µì  ëŒ€ê¸° ì „ëµ"""

    # Level 1: ë¹ ë¥¸ DOM ë¡œë“œ
    self.page.goto(url, wait_until="domcontentloaded", timeout=60000)

    # Level 2: ë„¤íŠ¸ì›Œí¬ ì•ˆì •í™” (íƒ€ì„ì•„ì›ƒ í—ˆìš©)
    try:
        self.page.wait_for_load_state("networkidle", timeout=10000)
    except:
        pass  # React SPAëŠ” ì™„ì „í•œ idle ìƒíƒœì— ë„ë‹¬í•˜ì§€ ëª»í•  ìˆ˜ ìˆìŒ

    # Level 3: ì‹¤ì œ ì½˜í…ì¸  ëŒ€ê¸°
    self.page.wait_for_selector('.recruitTitle', timeout=15000, state="visible")

    # Level 4: React ë Œë”ë§ ì•ˆì •í™”
    time.sleep(3)

    # JavaScriptë¡œ ë°ì´í„° ì¶”ì¶œ
    jobs_data = self.page.evaluate("""
        () => {
            const jobs = [];
            const recruitTitles = document.querySelectorAll('.recruitTitle');

            recruitTitles.forEach(titleEl => {
                let container = titleEl.closest('a[href*="/recruitment/recruits/"]');
                if (container) {
                    jobs.push({
                        title: titleEl.innerText.trim(),
                        company: titleEl.innerText.trim(),
                        content: container.querySelector('.recruitContent')?.innerText.trim() || '',
                        date: container.querySelector('.recruitDate')?.innerText.trim() || '',
                        link: container.href || ''
                    });
                }
            });
            return jobs;
        }
    """)

    return jobs_data
```

### 3. ë¶„ì„ ì—”ì§„ íŒ¨í„´

```python
from analyzers.keyword_detector import KeywordDetector
from analyzers.risk_scorer import RiskScorer

# í‚¤ì›Œë“œ íƒì§€
detector = KeywordDetector(
    keywords_csv="config/keywords.csv",
    patterns_csv="config/patterns.csv"
)

# ìœ„í—˜ë„ ì ìˆ˜ ê³„ì‚°
scorer = RiskScorer()

# ë¶„ì„ ì‹¤í–‰
for job in jobs:
    # 1. í‚¤ì›Œë“œ íƒì§€
    detection_result = detector.analyze(job)

    # 2. ìœ„í—˜ë„ ì ìˆ˜ ê³„ì‚°
    risk_result = scorer.calculate_risk_score(detection_result)

    # 3. ê²°ê³¼ í™•ì¸
    if risk_result['risk_level'] == 'ê³ ìœ„í—˜':
        print(f"âš ï¸ ê³ ìœ„í—˜ ê³µê³  ë°œê²¬: {job['title']}")
        print(f"   ì ìˆ˜: {risk_result['final_score']}")
        print(f"   ìœ„í—˜ ìš”ì¸: {risk_result['risk_factors']}")
```

### 4. ë°ì´í„°ë² ì´ìŠ¤ íŒ¨í„´ (Repository)

```python
from database.repositories import JobRepository, AnalysisRepository

# Repository ì´ˆê¸°í™”
job_repo = JobRepository(db_path="data/recruitment.db")
analysis_repo = AnalysisRepository(db_path="data/recruitment.db")

# ê³µê³  ì €ì¥
job_id = job_repo.insert_job({
    "title": "ë°˜ë„ì²´ ê³µì • ì—”ì§€ë‹ˆì–´",
    "company": "ê¸€ë¡œë²Œ R&D",
    "location": "ì¤‘êµ­ ìƒí•˜ì´",
    # ... ê¸°íƒ€ í•„ë“œ
})

# ë¶„ì„ ê²°ê³¼ ì €ì¥
analysis_repo.save_analysis(job_id, detection_result, risk_result)
```

## í•µì‹¬ ê°œë…

### 1. 3ë‹¨ê³„ í‚¤ì›Œë“œ íƒì§€ ì‹œìŠ¤í…œ

| Tier | ì¹´í…Œê³ ë¦¬ | ì˜ˆì‹œ í‚¤ì›Œë“œ | ê°€ì¤‘ì¹˜ |
|------|---------|------------|-------|
| 1ì°¨ | ê¸°ìˆ  í‚¤ì›Œë“œ | ë°˜ë„ì²´, OLED, ì´ì°¨ì „ì§€, AI | 8-10ì  |
| 2ì°¨ | ì˜ì‹¬ íŒ¨í„´ | í•´ì™¸í˜‘ì—…, ì¤‘êµ­ì–´í•„ìˆ˜, ê¸°ìˆ ì´ì „ | 12-25ì  |
| 3ì°¨ | ìœ„í—˜ í‚¤ì›Œë“œ | ê¸‰êµ¬, ë¹„ìí•„ìš”ì—†ìŒ, í˜„ê¸ˆì§€ê¸‰ | 20-25ì  |

### 2. ë³µí•© íŒ¨í„´ ë§¤ì¹­

2-3ê°œ í‚¤ì›Œë“œ AND ì¡°í•©ìœ¼ë¡œ ê³ ìœ„í—˜ íŒ¨í„´ íƒì§€:

```python
# ì˜ˆì‹œ: "ê¸°ìˆ  + ì¤‘êµ­ + ê¸‰êµ¬" íŒ¨í„´
{
    "pattern_name": "ê¸°ìˆ ìœ ì¶œ_ì¤‘êµ­_ê¸‰êµ¬",
    "keywords": ["ë°˜ë„ì²´", "ì¤‘êµ­ì–´", "ê¸‰êµ¬"],
    "operator": "AND",
    "score": 35
}
```

### 3. ìœ„í—˜ë„ ì ìˆ˜ ê³„ì‚°

```python
# ê¸°ë³¸ ì ìˆ˜ = Tier1 + Tier2 + Tier3 + Patterns
base_score = sum(tier1_weights) + sum(tier2_weights) + sum(tier3_weights) + sum(pattern_scores)

# ë³µí•© ì¡°ê±´ ê°€ì¤‘ì¹˜
combo_multiplier = 1.0
if tier1_count >= 2 and tier2_count >= 1:
    combo_multiplier += 0.5  # 1.5x
if tier3_count >= 1:
    combo_multiplier += 0.5  # 2.0x

# ìµœì¢… ì ìˆ˜
final_score = base_score * combo_multiplier
```

### 4. ìœ„í—˜ ë“±ê¸‰ ë¶„ë¥˜

- **ê³ ìœ„í—˜** (100ì  ì´ìƒ): ì¦‰ì‹œ ê²€í†  í•„ìš”
- **ì¤‘ìœ„í—˜** (50-99ì ): ì£¼ì˜ ê¹Šê²Œ ëª¨ë‹ˆí„°ë§
- **ì €ìœ„í—˜** (50ì  ë¯¸ë§Œ): ì¼ë°˜ ê³µê³ 

## Bot Detection íšŒí”¼ ê¸°ë²•

### 1. ë¸Œë¼ìš°ì € ì„¤ì •

```python
args = [
    '--disable-blink-features=AutomationControlled',  # ìë™í™” ì œì–´ ê¸°ëŠ¥ ë¹„í™œì„±í™”
    '--no-sandbox',                                   # ìƒŒë“œë°•ìŠ¤ ë¹„í™œì„±í™”
    '--disable-dev-shm-usage',                        # ê³µìœ  ë©”ëª¨ë¦¬ ì‚¬ìš© ë¹„í™œì„±í™”
]
```

### 2. User-Agent ì„¤ì •

```python
user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
```

### 3. WebDriver ì†ì„± ì œê±°

```python
page.add_init_script("""
    Object.defineProperty(navigator, 'webdriver', {
        get: () => undefined
    });
""")
```

## ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ

### jobs í…Œì´ë¸”
```sql
CREATE TABLE jobs (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    title TEXT,
    company TEXT,
    location TEXT,
    salary TEXT,
    conditions TEXT,
    recruit_summary TEXT,
    detail TEXT,
    url TEXT UNIQUE,
    posted_date TEXT,
    source_site TEXT,
    search_keyword TEXT,
    crawled_at TEXT,
    crawled_date TEXT,
    crawled_weekday TEXT,
    crawled_hour INTEGER
)
```

### keyword_matches í…Œì´ë¸”
```sql
CREATE TABLE keyword_matches (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    job_id INTEGER,
    keyword TEXT,
    tier INTEGER,
    category TEXT,
    weight INTEGER,
    positions TEXT,
    FOREIGN KEY (job_id) REFERENCES jobs (id)
)
```

### pattern_matches í…Œì´ë¸”
```sql
CREATE TABLE pattern_matches (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    job_id INTEGER,
    pattern_name TEXT,
    keywords TEXT,
    score INTEGER,
    FOREIGN KEY (job_id) REFERENCES jobs (id)
)
```

### risk_analysis í…Œì´ë¸”
```sql
CREATE TABLE risk_analysis (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    job_id INTEGER UNIQUE,
    base_score REAL,
    combo_multiplier REAL,
    final_score REAL,
    risk_level TEXT,
    risk_factors TEXT,
    recommendations TEXT,
    analysis_summary TEXT,
    FOREIGN KEY (job_id) REFERENCES jobs (id)
)
```

## ì¼ë°˜ì ì¸ ë¬¸ì œ í•´ê²°

### 1. Bot Detection ì˜¤ë¥˜
**ì¦ìƒ**: 403 Forbidden ë˜ëŠ” ë¹ˆ í˜ì´ì§€
**í•´ê²°ì±…**:
- `--no-headless` í”Œë˜ê·¸ë¡œ ë¸Œë¼ìš°ì € í‘œì‹œí•˜ì—¬ ë””ë²„ê¹…
- User-Agent ë° webdriver ì†ì„± í™•ì¸
- ëŒ€ê¸° ì‹œê°„ ì¦ê°€ (time.sleep ê°’ ì¡°ì •)

### 2. React SPA ì½˜í…ì¸  ë¡œë“œ ì‹¤íŒ¨
**ì¦ìƒ**: ë¹ˆ ë°ì´í„° ë˜ëŠ” selector ì˜¤ë¥˜
**í•´ê²°ì±…**:
- 4ë‹¨ê³„ ê³„ì¸µì  ëŒ€ê¸° ì „ëµ ì‚¬ìš©
- networkidle íƒ€ì„ì•„ì›ƒ í—ˆìš© (try-except)
- ìµœì¢… sleep ì‹œê°„ ì¦ê°€ (3ì´ˆ â†’ 5ì´ˆ)

### 3. í‚¤ì›Œë“œ ë§¤ì¹­ ì‹¤íŒ¨
**ì¦ìƒ**: ì˜ˆìƒë˜ëŠ” ê³µê³ ê°€ íƒì§€ë˜ì§€ ì•ŠìŒ
**í•´ê²°ì±…**:
- config/keywords.csv í™•ì¸ ë° í‚¤ì›Œë“œ ì¶”ê°€
- í…ìŠ¤íŠ¸ ì •ì œ ë¡œì§ í™•ì¸ (utils/text_utils.py)
- ë¡œê·¸ í™œì„±í™”í•˜ì—¬ ë§¤ì¹­ ê³¼ì • ì¶”ì 

## ê°œë°œ ê°€ì´ë“œ

### ìƒˆë¡œìš´ í¬ë¡¤ëŸ¬ ì¶”ê°€

1. `sites/[ì‚¬ì´íŠ¸ëª…]/` ë””ë ‰í† ë¦¬ ìƒì„±
2. `config.json` ì‘ì„± (base_url, selectors ë“±)
3. `crawler.py` êµ¬í˜„ (ê¸°ì¡´ íŒ¨í„´ ì°¸ê³ )
4. `__init__.py`ì— export ì¶”ê°€
5. `main.py`ì— ì‚¬ì´íŠ¸ ë“±ë¡

### ìƒˆë¡œìš´ í‚¤ì›Œë“œ ì¶”ê°€

1. `config/keywords.csv` í¸ì§‘
2. í˜•ì‹: `tier,category,keyword,weight`
3. ì˜ˆì‹œ: `1,í•µì‹¬ê¸°ìˆ ,ì–‘ìì»´í“¨í„°,10`

### ìƒˆë¡œìš´ íŒ¨í„´ ì¶”ê°€

1. `config/patterns.csv` í¸ì§‘
2. í˜•ì‹: `pattern_name,keyword1,keyword2,keyword3,operator,score,description`
3. ì˜ˆì‹œ: `ì–‘ìê¸°ìˆ _í•´ì™¸_ê¸‰êµ¬,ì–‘ìì»´í“¨í„°,í•´ì™¸í˜‘ì—…,ê¸‰êµ¬,AND,40,ì–‘ìì»´í“¨í„° ê¸°ìˆ  í•´ì™¸ ìœ ì¶œ ì˜ì‹¬`

## ì„±ëŠ¥ ìµœì í™”

### 1. ë³‘ë ¬ í¬ë¡¤ë§
```python
# ì—¬ëŸ¬ ì‚°ì—… ë™ì‹œ í¬ë¡¤ë§
industries = ["ë°˜ë„ì²´", "ë””ìŠ¤í”Œë ˆì´", "ì´ì°¨ì „ì§€"]
with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
    futures = [executor.submit(crawler.crawl_industry, ind) for ind in industries]
```

### 2. ë°ì´í„°ë² ì´ìŠ¤ ë°°ì¹˜ ì €ì¥
```python
# í•œ ë²ˆì— ì—¬ëŸ¬ ë ˆì½”ë“œ ì €ì¥
job_repo.insert_jobs_batch(jobs_list)
```

### 3. ìºì‹±
```python
# ì¤‘ë³µ URL ë°©ì§€
visited_urls = set()
if url not in visited_urls:
    visited_urls.add(url)
    process_job(url)
```

## í…ŒìŠ¤íŠ¸

### ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
```bash
pytest tests/
```

### í†µí•© í…ŒìŠ¤íŠ¸
```bash
python test_analysis_system.py
```

### í¬ë¡¤ëŸ¬ ê°œë³„ í…ŒìŠ¤íŠ¸
```bash
python -m sites.jobkorea.crawler --keyword "ë°˜ë„ì²´" --max-jobs 10
python -m sites.hibrain.crawler --keyword "êµìˆ˜" --max-jobs 10
```

## ì°¸ê³  ë¬¸ì„œ

- [README.md](./README.md) - í”„ë¡œì íŠ¸ ì „ì²´ ê°œìš”
- [sites/hibrain/IMPLEMENTATION_NOTES.md](./sites/hibrain/IMPLEMENTATION_NOTES.md) - Hibrain êµ¬í˜„ ë…¸íŠ¸
- [sites/saramin/IMPLEMENTATION_NOTES.md](./sites/saramin/IMPLEMENTATION_NOTES.md) - Saramin êµ¬í˜„ ë…¸íŠ¸

## ê¸°ì—¬ ê°€ì´ë“œ

1. ìƒˆë¡œìš´ ê¸°ëŠ¥ ì¶”ê°€ ì‹œ í…ŒìŠ¤íŠ¸ ì½”ë“œ ì‘ì„±
2. í¬ë¡¤ëŸ¬ ì¶”ê°€ ì‹œ IMPLEMENTATION_NOTES.md ì‘ì„±
3. ì½”ë“œ ìŠ¤íƒ€ì¼: PEP 8 ì¤€ìˆ˜
4. ë¡œê¹…: utils.logger.setup_logger() ì‚¬ìš©
5. ì—ëŸ¬ ì²˜ë¦¬: try-exceptë¡œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬

## ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” ë‚´ë¶€ ì‚¬ìš©ì„ ìœ„í•œ ê²ƒì…ë‹ˆë‹¤.
